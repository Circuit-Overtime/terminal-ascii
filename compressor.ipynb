{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Block Average Compression ---\n",
      "Processing image 534x400 (3 channels) in 8x8 blocks...\n",
      "[✓] Processed test.jpg. Saved block average colors to test_blockavg.npz\n",
      "\n",
      "--- Compression Metrics ---\n",
      "    Original image file size (e.g., JPEG): 17281 bytes\n",
      "    Estimated original raw pixel data size: 640800 bytes\n",
      "    Compressed file size (.npz): 5474 bytes\n",
      "    Compression ratio (vs. raw data): 117.06x\n",
      "    Size comparison (vs. original file): 0.32x the size\n",
      "    Compressed file is smaller than original image file.\n",
      "\n",
      "    Note: This process is LOSSY for the original pixel data due to block averaging (detail within blocks is lost).\n",
      "\n",
      "--- Running Block Average Decompression ---\n",
      "Reconstructing image 534x400 from 67x50 blocks...\n",
      "[✓] Decompressed from test_blockavg.npz to decompressed_blockavg.jpg\n",
      "\n",
      "--- Decompression Metrics ---\n",
      "    Decompressed image file size (decompressed_blockavg.jpg): 8050 bytes\n",
      "    Note: This output image is an approximation due to lossy block averaging. Its file size depends on the output format's own compression (e.g., JPEG quality).\n",
      "\n",
      "--- Summary ---\n",
      "Original image: test.jpg (size reported during compression)\n",
      "Compressed data: test_blockavg.npz (size reported during compression)\n",
      "Decompressed image: decompressed_blockavg.jpg (size reported during decompression)\n",
      "\n",
      "To evaluate the compression method, compare the 'test_blockavg.npz' size to the estimated raw data size or the original file size as explained above.\n",
      "To evaluate the lossiness, compare the 'test.jpg' and 'decompressed_blockavg.jpg' visually.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the block size. This is the core parameter controlling compression/loss.\n",
    "# Smaller BLOCK_SIZE -> Less compression, less loss (higher fidelity)\n",
    "# Larger BLOCK_SIZE -> More compression, more loss (lower fidelity)\n",
    "BLOCK_SIZE = 2 # Increased block size for potentially better compression demonstration\n",
    "\n",
    "def get_block_average_color(image, y_start, x_start, block_size, img_h, img_w):\n",
    "    \"\"\"Calculates the average BGR color for a block.\"\"\"\n",
    "    y_end = min(y_start + block_size, img_h)\n",
    "    x_end = min(x_start + block_size, img_w)\n",
    "    block = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    if block.size == 0:\n",
    "         return np.array([0, 0, 0], dtype=np.uint8)\n",
    "\n",
    "    avg_color = block.mean(axis=(0, 1))\n",
    "    return avg_color.astype(np.uint8)\n",
    "\n",
    "def compress_image_block_average(image_path, output_path=\"test_blockavg.npz\", block_size=BLOCK_SIZE):\n",
    "    \"\"\"\n",
    "    Compresses a color image by dividing it into blocks and storing the\n",
    "    average color of each block. Saves using numpy's compressed format (.npz).\n",
    "\n",
    "    This is a LOSSY compression method. The degree of loss depends on BLOCK_SIZE.\n",
    "    Compression is measured by the size of the .npz file compared to the\n",
    "    original raw pixel data size.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            print(f\"[!] Error: Could not load image from {image_path}\")\n",
    "            return\n",
    "\n",
    "        img_h, img_w, img_c = image.shape # Get height, width, and channels\n",
    "\n",
    "        # Calculate dimensions of the block grid\n",
    "        grid_h = (img_h + block_size - 1) // block_size\n",
    "        grid_w = (img_w + block_size - 1) // block_size\n",
    "\n",
    "        # Array to store the average color (B, G, R) for each block\n",
    "        block_avg_colors = np.zeros((grid_h, grid_w, 3), dtype=np.uint8)\n",
    "\n",
    "        print(f\"Processing image {img_w}x{img_h} ({img_c} channels) in {block_size}x{block_size} blocks...\")\n",
    "\n",
    "        for i in range(grid_h):\n",
    "            for j in range(grid_w):\n",
    "                y_start = i * block_size\n",
    "                x_start = j * block_size\n",
    "                avg_color = get_block_average_color(image, y_start, x_start, block_size, img_h, img_w)\n",
    "                block_avg_colors[i, j] = avg_color\n",
    "\n",
    "        # Save original dimensions, block size, and the block average colors\n",
    "        # using numpy's compressed format (.npz)\n",
    "        np.savez_compressed(output_path,\n",
    "                            original_height=img_h,\n",
    "                            original_width=img_w,\n",
    "                            block_size=block_size,\n",
    "                            block_avg_colors=block_avg_colors)\n",
    "\n",
    "        print(f\"[✓] Processed {image_path}. Saved block average colors to {output_path}\")\n",
    "\n",
    "        # --- Report Sizes ---\n",
    "        original_image_file_size = os.path.getsize(image_path)\n",
    "        compressed_npz_size = os.path.getsize(output_path)\n",
    "        # Estimate original raw pixel data size (assuming 1 byte per channel)\n",
    "        original_raw_size = img_h * img_w * img_c\n",
    "\n",
    "        print(f\"\\n--- Compression Metrics ---\")\n",
    "        print(f\"    Original image file size (e.g., JPEG): {original_image_file_size} bytes\")\n",
    "        print(f\"    Estimated original raw pixel data size: {original_raw_size} bytes\")\n",
    "        print(f\"    Compressed file size (.npz): {compressed_npz_size} bytes\")\n",
    "\n",
    "        # Compression is measured against the *raw* data\n",
    "        if original_raw_size > 0:\n",
    "             print(f\"    Compression ratio (vs. raw data): {original_raw_size / compressed_npz_size:.2f}x\")\n",
    "        # Comparison vs. the already compressed original file\n",
    "        if original_image_file_size > 0:\n",
    "            print(f\"    Size comparison (vs. original file): {compressed_npz_size / original_image_file_size:.2f}x the size\")\n",
    "            if compressed_npz_size < original_image_file_size:\n",
    "                 print(f\"    Compressed file is smaller than original image file.\")\n",
    "            else:\n",
    "                 print(f\"    Compressed file is larger than original image file (Original was already highly compressed).\")\n",
    "\n",
    "        print(f\"\\n    Note: This process is LOSSY for the original pixel data due to block averaging (detail within blocks is lost).\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] An error occurred during compression: {e}\")\n",
    "\n",
    "def decompress_block_average_to_image(input_path=\"test_blockavg.npz\", output_path=\"decompressed_blockavg.jpg\"):\n",
    "    \"\"\"\n",
    "    Decompresses block average color data back into a color image.\n",
    "    Saves the resulting image as a JPEG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the data from the numpy compressed file\n",
    "        data = np.load(input_path)\n",
    "\n",
    "        img_h = data['original_height']\n",
    "        img_w = data['original_width']\n",
    "        block_size = data['block_size']\n",
    "        block_avg_colors = data['block_avg_colors'] # Shape (grid_h, grid_w, 3)\n",
    "\n",
    "        grid_h, grid_w, _ = block_avg_colors.shape\n",
    "\n",
    "        # Create a blank image with the original dimensions\n",
    "        reconstructed_image = np.zeros((img_h, img_w, 3), dtype=np.uint8)\n",
    "\n",
    "        print(f\"Reconstructing image {img_w}x{img_h} from {grid_w}x{grid_h} blocks...\")\n",
    "\n",
    "        # Iterate through the stored block average colors\n",
    "        for i in range(grid_h):\n",
    "            for j in range(grid_w):\n",
    "                y_start = i * block_size\n",
    "                x_start = j * block_size\n",
    "                y_end = min(y_start + block_size, img_h)\n",
    "                x_end = min(x_start + block_size, img_w)\n",
    "\n",
    "                avg_color = block_avg_colors[i, j]\n",
    "\n",
    "                # Fill the corresponding block area\n",
    "                reconstructed_image[y_start:y_end, x_start:x_end] = avg_color\n",
    "\n",
    "        # Save the reconstructed color image\n",
    "        # You can control JPEG quality using a parameter like cv2.IMWRITE_JPEG_QUALITY\n",
    "        # Saving at lower quality might make the output file smaller, but adds more loss.\n",
    "        cv2.imwrite(output_path, reconstructed_image, [cv2.IMWRITE_JPEG_QUALITY, 90]) # Save with quality 90 (default is often 95)\n",
    "\n",
    "        print(f\"[✓] Decompressed from {input_path} to {output_path}\")\n",
    "\n",
    "        # --- Report Decompression Metrics ---\n",
    "        decompressed_image_file_size = os.path.getsize(output_path)\n",
    "        print(f\"\\n--- Decompression Metrics ---\")\n",
    "        print(f\"    Decompressed image file size ({os.path.basename(output_path)}): {decompressed_image_file_size} bytes\")\n",
    "        print(f\"    Note: This output image is an approximation due to lossy block averaging. Its file size depends on the output format's own compression (e.g., JPEG quality).\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[!] Error: Input file not found at {input_path}\")\n",
    "    except KeyError as e:\n",
    "         print(f\"[!] Error: Missing expected key in the compressed file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[!] An error occurred during decompression: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have a 'test.jpg' image in the same directory\n",
    "    # Or change the path to your image file. Use a color image!\n",
    "    input_image = \"test.jpg\" # Make sure test.jpg is a color image\n",
    "    compressed_file = \"test_blockavg.npz\"\n",
    "    decompressed_image = \"decompressed_blockavg.jpg\"\n",
    "\n",
    "    # --- Compression (Block Averaging) ---\n",
    "    # Experiment with different BLOCK_SIZE values (e.g., 4, 8, 16)\n",
    "    # Larger block size = more compression (smaller .npz file) = more loss (more blocky image)\n",
    "    print(\"--- Running Block Average Compression ---\")\n",
    "    compress_image_block_average(input_image, compressed_file, block_size=BLOCK_SIZE) # Try changing block_size here\n",
    "\n",
    "    print(\"\\n--- Running Block Average Decompression ---\")\n",
    "    decompress_block_average_to_image(compressed_file, decompressed_image)\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(f\"Original image: {input_image} (size reported during compression)\")\n",
    "    print(f\"Compressed data: {compressed_file} (size reported during compression)\")\n",
    "    print(f\"Decompressed image: {decompressed_image} (size reported during decompression)\")\n",
    "    print(f\"\\nTo evaluate the compression method, compare the '{compressed_file}' size to the estimated raw data size or the original file size as explained above.\")\n",
    "    print(f\"To evaluate the lossiness, compare the '{input_image}' and '{decompressed_image}' visually.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
